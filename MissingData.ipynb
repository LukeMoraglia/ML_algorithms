{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "949e9baa-0a07-481f-8e8d-20763ef69ea8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Missing Data\n",
    "\n",
    "Author: Luke Moraglia\n",
    "\n",
    "This notebook gives an overview of methods to handle missing data. It covers:\n",
    "1. Dropping rows or columns that contain NA values\n",
    "2. Mean and median imputation\n",
    "3. Multivariate feature imputation with `IterativeImputer`\n",
    "4. Nearest neighbors imputation with `KNNImputer`\n",
    "\n",
    "## Types of missing data\n",
    "\n",
    "*The information in this section is summarized from the Bhaskaran and Smeeth article linked below.*    \n",
    "Missing data can be categorized in three ways: missing completely at random (MCAR), missing at random (MAR), and missing not at random (MNAR).\n",
    "When a variable has observations that are MCAR, the missing observations are a random subset of the observations. This means that missing observations and present observations have similar distributions and there are not systematic differences between the missing and present observations. For example, if a sensor collecting data is randomly faulty, we would expect our missing observations to be a truly random subset of all the observations. \n",
    "When a variable has observations that are MAR, there could be systematic differences between the missing and present observations leading to different distributions, but these differences can be explained by other observed variables. For instance, we might have blood pressure data that are missing more often for younger patients, because a doctor is more likely to be certain to collect BP data on his older patients. Our younger patients are also likely to have lower blood pressures than the older patients, so we are guessing that our missing data will have a different distribution (lower mean) than our present data. This difference in distributions might make it seem like the data are not missing at random, but since we have also recorded the age of the patients, we can use age as a variable that explains the difference in blood pressure. This makes blood pressure MAR, which is valid for missing data methods like multiple imputation.  \n",
    "For variables with observations MNAR, imputation will be invalid since there are systematic differences between the missing and present observations that cannot be explained by other variables. For instance, a doctor is more likely to record BMI for a patient who is noticibly overweight, meaning that missing data will tend to have a distribution with lower BMIs. This cannot be explained by any other variables such as age or sex, so these data are MNAR. \n",
    "\n",
    "(Re)Sources:\n",
    "- [Abhishek Thakur and Rob Mulla missing data livestream](https://www.youtube.com/watch?v=EYySNJU8qR0&t=3127s) on which much of this code is based\n",
    "- [Jason Brownlee's Machine Learning Mastery](https://machinelearningmastery.com/handle-missing-data-python/) where the dataset inspiration comes from\n",
    "- [sklearn](https://scikit-learn.org/stable/modules/impute.html#)\n",
    "- [Article by Bhaskaran & Smeeth](https://academic.oup.com/ije/article/43/4/1336/2938944?login=true) on the difference between MCAR, MAR, and MNAR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594ec72c-5881-4b5e-8588-ba789cefbfb0",
   "metadata": {},
   "source": [
    "# Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3af5c085-7536-4ef1-aef2-1be001aed3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "from sklearn.datasets import fetch_covtype\n",
    "from numpy.random import default_rng\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a618f07-f049-4ce5-bfbf-2407371face4",
   "metadata": {},
   "source": [
    "# Load Data / Investigate Missing Data\n",
    "We will use the Diabetes dataset available from Jason Brownlee (link above). We have 8 numeric variables as our input variables and a binary outcome of diabetes present or absent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a0e9658-351e-4bce-9495-a2e1d20943a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"pregnant\", \"glucose\", \"BP\", \"skin_thick\", \"insulin\", \"BMI\", \"diab_ped_func\", \"age\", \"diabetes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebdafd39-ab03-4d3e-8efe-b19330b9666e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv\", names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42959c0b-799c-4b89-9f7a-4e210615cf9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>glucose</th>\n",
       "      <th>BP</th>\n",
       "      <th>skin_thick</th>\n",
       "      <th>insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>diab_ped_func</th>\n",
       "      <th>age</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         pregnant     glucose          BP  skin_thick     insulin         BMI  \\\n",
       "count  768.000000  768.000000  768.000000  768.000000  768.000000  768.000000   \n",
       "mean     3.845052  120.894531   69.105469   20.536458   79.799479   31.992578   \n",
       "std      3.369578   31.972618   19.355807   15.952218  115.244002    7.884160   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      1.000000   99.000000   62.000000    0.000000    0.000000   27.300000   \n",
       "50%      3.000000  117.000000   72.000000   23.000000   30.500000   32.000000   \n",
       "75%      6.000000  140.250000   80.000000   32.000000  127.250000   36.600000   \n",
       "max     17.000000  199.000000  122.000000   99.000000  846.000000   67.100000   \n",
       "\n",
       "       diab_ped_func         age    diabetes  \n",
       "count     768.000000  768.000000  768.000000  \n",
       "mean        0.471876   33.240885    0.348958  \n",
       "std         0.331329   11.760232    0.476951  \n",
       "min         0.078000   21.000000    0.000000  \n",
       "25%         0.243750   24.000000    0.000000  \n",
       "50%         0.372500   29.000000    0.000000  \n",
       "75%         0.626250   41.000000    1.000000  \n",
       "max         2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3d3af8-8eb2-4e27-9fd5-1a11d80bf4e1",
   "metadata": {},
   "source": [
    "In this data, missing values on several columns have been coded with '0'. This is confusing because is a numeric value and Python cannot treat it as missing. We can switch these values to `NaN` so that Python/pandas can treat it as a missing value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fabaaec-fecb-4de8-b610-c88725f079c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_missing = [\"glucose\", \"BP\", \"skin_thick\", \"insulin\", \"BMI\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9fcef63-5077-4542-9cad-0a2675f900a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>glucose</th>\n",
       "      <th>BP</th>\n",
       "      <th>skin_thick</th>\n",
       "      <th>insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>diab_ped_func</th>\n",
       "      <th>age</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnant  glucose    BP  skin_thick  insulin   BMI  diab_ped_func  age  \\\n",
       "0         6    148.0  72.0        35.0      NaN  33.6          0.627   50   \n",
       "1         1     85.0  66.0        29.0      NaN  26.6          0.351   31   \n",
       "2         8    183.0  64.0         NaN      NaN  23.3          0.672   32   \n",
       "3         1     89.0  66.0        23.0     94.0  28.1          0.167   21   \n",
       "4         0    137.0  40.0        35.0    168.0  43.1          2.288   33   \n",
       "\n",
       "   diabetes  \n",
       "0         1  \n",
       "1         0  \n",
       "2         1  \n",
       "3         0  \n",
       "4         1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace zeroes in these columns with NaN\n",
    "data[cols_missing] = data[cols_missing].replace(0, np.nan)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252b1bc3-cbda-4828-b6f6-af7bd8fc8b80",
   "metadata": {},
   "source": [
    "We can check how many missing values there are in each variable, as well as the percentage of missing values in each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4012e143-4d17-4913-81b5-737e4ebddbf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pregnant           0\n",
       "glucose            5\n",
       "BP                35\n",
       "skin_thick       227\n",
       "insulin          374\n",
       "BMI               11\n",
       "diab_ped_func      0\n",
       "age                0\n",
       "diabetes           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed98e916-a2a4-4fd2-ac7d-9c23a2a7e4d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pregnant         0.000000\n",
       "glucose          0.006510\n",
       "BP               0.045573\n",
       "skin_thick       0.295573\n",
       "insulin          0.486979\n",
       "BMI              0.014323\n",
       "diab_ped_func    0.000000\n",
       "age              0.000000\n",
       "diabetes         0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c95df2-f85b-46cc-96ff-c5301f32e72b",
   "metadata": {},
   "source": [
    "Finally we'll do a train test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fd9544d-80b4-4c7e-8733-6dc353e17134",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,:8]\n",
    "y = data.iloc[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e06a1ebb-17ba-439f-be7a-5d67eb04a364",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96203476-aa92-4b65-895b-7c198d7c8940",
   "metadata": {},
   "source": [
    "# Use missingness as a predictor\n",
    "\n",
    "We can create a new variable from each variable that has missing values. These new variables are indicator variables that are \"True\" if the observation had a missing value for that variable. This can give us an idea of if the fact that a value is missing is informative for predicting diabetes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf2619aa-9fa9-4507-aed7-810152afb0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_missing_tag = X_train[cols_missing].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7df51d0-7271-4b04-beb9-c120426e1501",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_missing_tag.columns = [f\"{c}_missing\" for c in cols_missing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d73fddc4-61cd-4caf-a301-bbd707011556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>glucose_missing</th>\n",
       "      <th>BP_missing</th>\n",
       "      <th>skin_thick_missing</th>\n",
       "      <th>insulin_missing</th>\n",
       "      <th>BMI_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     glucose_missing  BP_missing  skin_thick_missing  insulin_missing  \\\n",
       "353            False       False               False            False   \n",
       "711            False       False               False            False   \n",
       "373            False       False               False            False   \n",
       "46             False       False                True             True   \n",
       "682            False       False               False            False   \n",
       "\n",
       "     BMI_missing  \n",
       "353        False  \n",
       "711        False  \n",
       "373        False  \n",
       "46         False  \n",
       "682        False  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_missing_tag.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03e1f7cd-fbec-4a72-adb1-3e03a325a175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_eval(model, X, y):\n",
    "    y_pred = model.predict_proba(X)[:, 1]\n",
    "    print(f\"ROC-AUC: {roc_auc_score(y, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ab9fbcf-c498-4d76-89c1-0cb585e77b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.5232827102803738\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegressionCV(scoring=\"accuracy\")\n",
    "\n",
    "lr.fit(X_missing_tag, y_train)\n",
    "lr.score(X_missing_tag, y_train)\n",
    "\n",
    "model_eval(lr, X_missing_tag, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41ce6ce-5e74-485f-abc7-41d0153beaca",
   "metadata": {},
   "source": [
    "A quick logistic regression shows a ROC-AUC that is about what we would expect by chance alone, so the presence or absence of missing data does not appear to be predictive in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763547b0-3fe9-407b-be9e-95818fe17117",
   "metadata": {},
   "source": [
    "# Ways to handle missing data\n",
    "We will investigate a few ways to handle missing data. For each method, we'll see how a Gradient Boosting Classifier performs in terms of ROC-AUC on the data. In the video linked above, Rob Mulla is asked a few questions about what method should be used for a specific situation, and his answer consistently turned to the practical solution of \"Try them all and pick the one that performs best in your cross-validation.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48b0577e-3b59-4073-b3fb-350bd6ffe276",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingClassifier(random_state=42,\n",
    "                                   max_depth = 2,\n",
    "                                   n_estimators=20\n",
    "                                   )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8068d3-b77f-432a-a182-09128e5b1f5d",
   "metadata": {},
   "source": [
    "## Drop rows or columns with missing data\n",
    "One way to get data with no missing values is to drop any rows or any columns that have missing data. This has some clear disadvantages, the main one being that you are throwing away potentially valuable data. It also could be impractical in a real world setting where new observations will also have missing values. It would probably make more sense to have a model that is able to handle missing data rather than getting rid of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75e6e7b7-a39f-489b-b130-6af71fa44126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392, 8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop NA rows\n",
    "data_drop_rows = data.dropna(axis=0)\n",
    "X_drop_rows = data_drop_rows.iloc[:,:8]\n",
    "y_drop_rows = data_drop_rows.iloc[:,8]\n",
    "X_drop_rows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69338b7d-e217-4df0-95af-a98faa585705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.9049324721080447\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_drop_rows, y_drop_rows)\n",
    "model_eval(model, X_drop_rows, y_drop_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c54be0b-18c8-4ff6-a01b-5e5b358e215c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop NA columns\n",
    "data_drop_cols = data.dropna(axis=1)\n",
    "X_drop_cols = data_drop_cols.drop(\"diabetes\", axis=1)\n",
    "y_drop_cols = data_drop_cols[\"diabetes\"]\n",
    "X_drop_cols.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "551f0767-17cb-4f32-a76a-6e88770ccb33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.758794776119403\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_drop_cols, y_drop_cols)\n",
    "model_eval(model, X_drop_cols, y_drop_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d30dc8b-dc66-403c-ab34-ef61cfcf787c",
   "metadata": {},
   "source": [
    "## Mean / median imputation\n",
    "\n",
    "We can replace (impute) missing values with some other value. Two common values for numeric predictors are the mean and median of the variable. If we had categorical predictors we could also use mode imputation, though this feels less intuitive than the mean and median situation.\n",
    "\n",
    "The `SimpleImputer` is a class to easily impute the mean, median, or mode for each variable in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04f946bc-a1e3-47f4-93dc-4b49608c8a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute with mean\n",
    "imptr = SimpleImputer(strategy=\"mean\", add_indicator=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36b7883b-b09a-4d20-a5f9-407410ede3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mean_imp = imptr.fit_transform(X_train)\n",
    "X_test_mean_imp = imptr.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f37e27e0-2544-4255-b505-5a62350849ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.8037037037037036\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_mean_imp, y_train)\n",
    "model_eval(model, X_test_mean_imp, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff9744dd-aecb-4f8d-99c8-e2838db7d38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute with median\n",
    "imptr = SimpleImputer(strategy=\"median\", add_indicator=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f381ef5e-bbc3-4d78-8cfa-8607c705df2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_med_imp = imptr.fit_transform(X_train)\n",
    "X_test_med_imp = imptr.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3cd99bd6-0491-470a-94cd-bdad807d32f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.8037037037037036\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_med_imp, y_train)\n",
    "model_eval(model, X_test_med_imp, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840d6720-7151-431f-8af7-6c207f558987",
   "metadata": {},
   "source": [
    "## Multivariate imputation\n",
    "Mean and median imputation rely only on the values of the variable being imputed. In contrast, we could use the values of the other input variables to try to predict the variable that is being imputed. A regressor is fit that predicts that variable being imputed from the other variables, and the estimates for the missing values from this regressor are used as the imputed values.\n",
    "\n",
    "The `IterativeImputer` from scikit-learn uses a Bayesian Ridge Regressor by default, but you can be used with any estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6514cb20-82a5-4987-8705-5911c91c5223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterative imputer\n",
    "it_imputer = IterativeImputer(max_iter=10, random_state=42)\n",
    "X_train_it_imp = it_imputer.fit_transform(X_train)\n",
    "X_test_it_imp = it_imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ea7d4d7-fc3f-411a-a5c0-5c5b09627d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.7957407407407406\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_it_imp, y_train)\n",
    "model_eval(model, X_test_it_imp, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5ead90-7827-4200-87d8-da940bbe6dd1",
   "metadata": {},
   "source": [
    "## Nearest Neighbor Imputation\n",
    "We could also impute values by using the average of the observation's $k$ nearest neighbors. This is implemented by the `KNNImputer` with the default of `n_neighbors=5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d45b5a6b-f1cd-4538-8b93-70839d35f0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN imputer\n",
    "knn_imputer = KNNImputer()\n",
    "X_train_knn_imp = knn_imputer.fit_transform(X_train)\n",
    "X_test_knn_imp = knn_imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7ae792d8-7995-40a4-9381-b6f68783c537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.8158333333333333\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_knn_imp, y_train)\n",
    "model_eval(model, X_test_knn_imp, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_ml",
   "language": "python",
   "name": "venv_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
